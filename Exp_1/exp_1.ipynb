{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment #1: Manipulating Datasets using Pandas\n",
    "<b>Mohammed Abed Alkareem</b>\n",
    "<b>1210708</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Series and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Creating Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: \n",
    "Create a simple Pandas Series from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3,4,5]\n",
    "\n",
    "my_series = pd.Series(a)\n",
    "print(my_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: \n",
    "Create a simple Pandas Series from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day1    420\n",
      "day2    380\n",
      "day3    390\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
    "\n",
    "#create a series\n",
    "my_series = pd.Series(calories)\n",
    "\n",
    "print(my_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Creating Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: \n",
    "Create a DataFrame from a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n"
     ]
    }
   ],
   "source": [
    "d = pd.Series([1,2,3,4,5])\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4: \n",
    "Creating DataFrame from a Dictionary of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age\n",
      "0  Ahmad   22\n",
      "1    Ali   25\n",
      "2   Nora   24\n",
      "3   Sara   28\n"
     ]
    }
   ],
   "source": [
    "data = {'Name': [\"Ahmad\", \"Ali\", \"Nora\", \"Sara\"],\n",
    "        'Age': [22, 25, 24, 28]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 5: \n",
    "Creating dataframe from two series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calories  duration\n",
      "0       420        50\n",
      "1       380        40\n",
      "2       390        45\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "        \"calories\": [420, 380, 390],\n",
    "        \"duration\": [50, 40, 45]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 6: \n",
    "Load a CSV file into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Waiter  total_bill   tip smoker   day   time  size\n",
      "0       10       27.20  4.00     No  Thur  Lunch     4\n",
      "1       10       22.76  3.00     No  Thur  Lunch     2\n",
      "2       11       17.29  2.71     No  Thur  Lunch     2\n",
      "3       11       19.44  3.00    Yes  Thur  Lunch     2\n",
      "4       33       16.66  3.40     No  Thur  Lunch     2\n",
      "5       33       10.07  1.83     No  Thur  Lunch     1\n",
      "6       30       32.68  5.00    Yes  Thur  Lunch     2\n",
      "7       30       15.98  2.03     No  Thur  Lunch     2\n",
      "8       12       34.83  5.17     No  Thur  Lunch     4\n",
      "9       10       13.03  2.00     No  Thur  Lunch     2\n",
      "10      11       18.28  4.00     No  Thur  Lunch     2\n",
      "11      12       24.71  5.85     No  Thur  Lunch     2\n",
      "12      33       21.16  3.00     No  Thur  Lunch     2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Lunch.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Exploring DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 7: \n",
    "using .head() function to print the first five rows of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Waiter  total_bill   tip smoker  day    time  size\n",
      "0      10       16.99  1.01     No  Sun  Dinner     2\n",
      "1      10       10.34  1.66     No  Sun  Dinner     3\n",
      "2      11       21.01  3.50     No  Sun  Dinner     3\n",
      "3      11       23.68  3.31     No  Sun  Dinner     2\n",
      "4      22       24.59  3.61     No  Sun  Dinner     4\n",
      "-----------------\n",
      "   Waiter  total_bill   tip smoker  day    time  size\n",
      "0      10       16.99  1.01     No  Sun  Dinner     2\n",
      "1      10       10.34  1.66     No  Sun  Dinner     3\n",
      "2      11       21.01  3.50     No  Sun  Dinner     3\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Dinner.csv')\n",
    "print(df.head())\n",
    "print(\"-----------------\")\n",
    "print(df.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 8: \n",
    "using .tail() function to print the last five rows of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Waiter       type\n",
      "1      11  part time\n",
      "2      33  full time\n",
      "3      30  full time\n",
      "4      12  part time\n",
      "5      20  part time\n",
      "-----------------\n",
      "   Waiter       type\n",
      "3      30  full time\n",
      "4      12  part time\n",
      "5      20  part time\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Waiters.csv')\n",
    "print(df.tail())\n",
    "print(\"-----------------\")\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 9\n",
    "printing the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 7)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Lunch.csv')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "#(rows, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame has a shape of (13, 7) , this implies that the DataFrame is made up of 13 rows and 7 columns of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 10\n",
    "using .info() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Waiter      13 non-null     int64  \n",
      " 1   total_bill  13 non-null     float64\n",
      " 2   tip         13 non-null     float64\n",
      " 3   smoker      13 non-null     object \n",
      " 4   day         13 non-null     object \n",
      " 5   time        13 non-null     object \n",
      " 6   size        13 non-null     int64  \n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 860.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Lunch.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 DataFrames Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n",
      "0      1     11     21     31     41     51     61     71     81\n",
      "1      2     12     22     32     42     52     62     72     82\n",
      "2      3     13     23     33     43     53     63     73     83\n",
      "3      4     14     24     34     44     54     64     74     84\n",
      "4      5     15     25     35     45     55     65     75     85\n",
      "5      6     16     26     36     46     56     66     76     86\n",
      "6      7     17     27     37     47     57     67     77     87\n",
      "7      8     18     28     38     48     58     68     78     88\n",
      "8      9     19     29     39     49     59     69     79     89\n",
      "9     10     20     30     40     50     60     70     80     90\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "                    {\n",
    "                        'col_1': list(range(1, 11)), \n",
    "                        'col_2': list(range(11, 21)), \n",
    "                        'col_3': list(range(21, 31)), \n",
    "                        'col_4': list(range(31, 41)), \n",
    "                        'col_5': list(range(41, 51)), \n",
    "                        'col_6': list(range(51, 61)), \n",
    "                        'col_7': list(range(61, 71)), \n",
    "                        'col_8': list(range(71, 81)), \n",
    "                        'col_9': list(range(81, 91))\n",
    "                    }\n",
    "                )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Label-based Dataframe Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8',\n",
      "       'col_9'],\n",
      "      dtype='object')\n",
      "------------------\n",
      "RangeIndex(start=0, stop=10, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(\"------------------\")\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 11:\n",
    "printing the second column using the label indexing operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11\n",
      "1    12\n",
      "2    13\n",
      "3    14\n",
      "4    15\n",
      "5    16\n",
      "6    17\n",
      "7    18\n",
      "8    19\n",
      "9    20\n",
      "Name: col_2, dtype: int64\n",
      "------------------\n",
      "   col_5  col_1  col_8\n",
      "0     41      1     71\n",
      "1     42      2     72\n",
      "2     43      3     73\n",
      "3     44      4     74\n",
      "4     45      5     75\n",
      "5     46      6     76\n",
      "6     47      7     77\n",
      "7     48      8     78\n",
      "8     49      9     79\n",
      "9     50     10     80\n",
      "------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['col_100'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_8\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcol_5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcol_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcol_8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcol_100\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['col_100'] not in index\""
     ]
    }
   ],
   "source": [
    "print(df['col_2'])\n",
    "print(\"------------------\")\n",
    "print(df[['col_5', 'col_1', 'col_8']])\n",
    "print(\"------------------\")\n",
    "print(df[['col_5', 'col_1', 'col_8', 'col_100']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when choosing multiple existing columns it returns them\n",
    "while if the column not exists it gives error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example  12:\n",
    "selecting the values of the first row of the DataFrame using the loc  indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_1     1\n",
      "col_2    11\n",
      "col_3    21\n",
      "col_4    31\n",
      "col_5    41\n",
      "col_6    51\n",
      "col_7    61\n",
      "col_8    71\n",
      "col_9    81\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Index (row name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = ['row_1', 'row_2', 'row_3', 'row_4', 'row_5', 'row_6',\n",
    "'row_7', 'row_8', 'row_9', 'row_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n",
      "row_6      6     16     26     36     46     56     66     76     86\n",
      "row_2      2     12     22     32     42     52     62     72     82\n",
      "row_9      9     19     29     39     49     59     69     79     89\n",
      "------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['row_100'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_6\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_9\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrow_6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrow_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrow_9\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrow_100\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_7\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_9\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['row_100'] not in index\""
     ]
    }
   ],
   "source": [
    "print(df.loc[['row_6', 'row_2', 'row_9']])\n",
    "print(\"------------------\")\n",
    "print(df.loc[['row_6', 'row_2', 'row_9', 'row_100']])\n",
    "print(\"------------------\")\n",
    "print(df.loc['row_7':'row_9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when choosing multiple existing rows it returns them\n",
    "while if the row not exists it gives error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: \n",
    "Print the first 4 rows using the slicing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n",
      "row_1      1     11     21     31     41     51     61     71     81\n",
      "row_2      2     12     22     32     42     52     62     72     82\n",
      "row_3      3     13     23     33     43     53     63     73     83\n",
      "row_4      4     14     24     34     44     54     64     74     84\n"
     ]
    }
   ],
   "source": [
    "print(df.loc['row_1':'row_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: \n",
    "Print the last row with columns from col_5 to col_7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_5    50\n",
      "col_6    60\n",
      "col_7    70\n",
      "Name: row_10, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.loc['row_10', 'col_5':'col_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at['row_6', 'col_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Position-based Dataframe Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n",
      "row_4      4     14     24     34     44     54     64     74     84\n",
      "row_5      5     15     25     35     45     55     65     75     85\n",
      "row_6      6     16     26     36     46     56     66     76     86\n",
      "------------------\n",
      "col_1     4\n",
      "col_2    14\n",
      "col_3    24\n",
      "col_4    34\n",
      "col_5    44\n",
      "col_6    54\n",
      "col_7    64\n",
      "col_8    74\n",
      "col_9    84\n",
      "Name: row_4, dtype: int64\n",
      "------------------\n",
      "        col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n",
      "row_10     10     20     30     40     50     60     70     80     90\n",
      "row_9       9     19     29     39     49     59     69     79     89\n",
      "row_8       8     18     28     38     48     58     68     78     88\n",
      "------------------\n",
      "col_3    21\n",
      "col_9    81\n",
      "col_4    31\n",
      "Name: row_1, dtype: int64\n",
      "------------------\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(df[3:6])\n",
    "print(\"------------------\")\n",
    "print(df.iloc[3])\n",
    "print(\"------------------\")\n",
    "print(df.iloc[[9, 8, 7]])\n",
    "print(\"------------------\")\n",
    "print(df.iloc[0, [2, 8, 3]])\n",
    "print(\"------------------\")\n",
    "print(df.iat[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **df[3:6]** returns from the fourth to the sixth row\n",
    "- **df.iloc[3]** returns the fourth row (iloc parameter is the index of the row)\n",
    "- **df.iloc[[9, 8, 7]]** returns the 10th , 9th , 7th rows with all columns\n",
    "- **df.iloc[0, [2, 8, 3]]** returns the values from the first row of df at the 3rd, 9th, and 4th columns\n",
    "- **df.iat[1, 2]** returns the value located at the second row (index 1) and the third column (index 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: \n",
    "Use iloc with position-based indexing to select rows 8, and 1 and columns 5 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_5  col_6  col_7  col_8  col_9\n",
      "8     49     59     69     79     89\n",
      "1     42     52     62     72     82\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[[8,1],4:9])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: \n",
    "Use iloc with position-based indexing to select all rows and columns 1, 3, and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col_2  col_4  col_8\n",
      "row_1      11     31     71\n",
      "row_2      12     32     72\n",
      "row_3      13     33     73\n",
      "row_4      14     34     74\n",
      "row_5      15     35     75\n",
      "row_6      16     36     76\n",
      "row_7      17     37     77\n",
      "row_8      18     38     78\n",
      "row_9      19     39     79\n",
      "row_10     20     40     80\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[:, [1, 3, 7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Boolean Dataframe Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: \n",
    "Selecting all the rows of the dataframe where the value of col_2 is NOT greater than 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "Name: col_2, dtype: bool\n",
      "<class 'pandas.core.series.Series'>\n",
      "=====================================\n",
      "   col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n",
      "0      1     11     21     31     41     51     61     71     81\n",
      "1      2     12     22     32     42     52     62     72     82\n",
      "2      3     13     23     33     43     53     63     73     83\n",
      "3      4     14     24     34     44     54     64     74     84\n",
      "4      5     15     25     35     45     55     65     75     85\n"
     ]
    }
   ],
   "source": [
    "condition = df['col_2'] <= 15\n",
    "print(condition)\n",
    "print(type(condition))\n",
    "print(\"=====================================\")\n",
    "print(df[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6: \n",
    "Selecting all the rows of the dataframe where the value of col_2 is greater than 15 but not equal to 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9\n",
      "row_6       6     16     26     36     46     56     66     76     86\n",
      "row_7       7     17     27     37     47     57     67     77     87\n",
      "row_8       8     18     28     38     48     58     68     78     88\n",
      "row_10     10     20     30     40     50     60     70     80     90\n"
     ]
    }
   ],
   "source": [
    "condition1 = df['col_2'] > 15 \n",
    "condition2 = df['col_2'] != 19\n",
    "condition = condition1 & condition2\n",
    "print(df[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Saving Dataframe to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 13:\n",
    "Saving a DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataframe\n",
    "Biodata = {'Name': ['Ahmad', 'Ali', 'Omar', 'Hamzah'],\n",
    "'Age': [28, 23, 35, 31],\n",
    "'Gender': ['M', 'F', 'M', 'F']\n",
    "}\n",
    "df = pd.DataFrame(Biodata)\n",
    "# Save the dataframe to a CSV file\n",
    "df.to_csv('Biodata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7: \n",
    "Save the above dataframe using tab-separated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataframe\n",
    "Biodata = {'Name': ['Ahmad', 'Ali', 'Omar', 'Hamzah'],\n",
    "'Age': [28, 23, 35, 31],\n",
    "'Gender': ['M', 'F', 'M', 'F']\n",
    "}\n",
    "df = pd.DataFrame(Biodata)\n",
    "# Save the dataframe to a CSV file\n",
    "df.to_csv('Biodata.csv', sep=\"\\t\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Dealing with Rows and Columns in Panda's DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1 Column Addition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 14:\n",
    "Column addition using the basic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Height Qualification\n",
      "0   Ahmad     5.1           Msc\n",
      "1     Ali     6.2            MA\n",
      "2    Omar     5.1           Msc\n",
      "3  Hamzah     5.2           Msc\n",
      "-------------------------------\n",
      "     Name  Height Qualification    Address\n",
      "0   Ahmad     5.1           Msc      Delhi\n",
      "1     Ali     6.2            MA  Bangalore\n",
      "2    Omar     5.1           Msc    Chennai\n",
      "3  Hamzah     5.2           Msc      Patna\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Define a dictionary containing Students data\n",
    "data = {'Name': ['Ahmad', 'Ali', 'Omar', 'Hamzah'],\n",
    "'Height': [5.1, 6.2, 5.1, 5.2],\n",
    "'Qualification': ['Msc', 'MA', 'Msc', 'Msc']}\n",
    "# Convert the dictionary into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(\"-------------------------------\")\n",
    "# Declare a list that is to be converted into a column\n",
    "address = ['Delhi', 'Bangalore', 'Chennai', 'Patna']\n",
    "# Using 'Address' as the column name and equating it to the list\n",
    "df['Address'] = address\n",
    "# Observe the result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8: \n",
    "Add a new column (on the dataframe above) named Age with the following values [21, 23, 24, 21] and make it the third column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Height  Age Qualification    Address\n",
      "0   Ahmad     5.1   21           Msc      Delhi\n",
      "1     Ali     6.2   23            MA  Bangalore\n",
      "2    Omar     5.1   24           Msc    Chennai\n",
      "3  Hamzah     5.2   21           Msc      Patna\n"
     ]
    }
   ],
   "source": [
    "df.insert(column=\"Age\", value=[21, 23, 24, 21], loc=2)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.2 Column Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 15:\n",
    "Deleting a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Height Qualification  Age\n",
      "0   Ahmad     5.1           Msc   21\n",
      "1     Ali     6.2            MA   23\n",
      "2    Omar     5.1           Msc   24\n",
      "3  Hamzah     5.2           Msc   21\n",
      "===============================\n",
      "     Name  Height Qualification  Age\n",
      "0   Ahmad     5.1           Msc   21\n",
      "1     Ali     6.2            MA   23\n",
      "2    Omar     5.1           Msc   24\n",
      "3  Hamzah     5.2           Msc   21\n",
      "-------------------------------\n",
      "     Name Qualification  Age\n",
      "0   Ahmad           Msc   21\n",
      "1     Ali            MA   23\n",
      "2    Omar           Msc   24\n",
      "3  Hamzah           Msc   21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Define a dictionary containing Students data\n",
    "data = {'Name': ['Ahmad', 'Ali', 'Omar', 'Hamzah'],\n",
    "    'Height': [5.1, 6.2, 5.1, 5.2],\n",
    "    'Qualification': ['Msc', 'MA', 'Msc', 'Msc'],\n",
    "    'Age': [21, 23, 24, 21]\n",
    "    }\n",
    "# Convert the dictionary into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(\"===============================\")\n",
    "# dropping passed columns\n",
    "df1 = df.drop([\"Height\"], axis = 1)\n",
    "# Observe the result\n",
    "print(df)\n",
    "print(\"-------------------------------\")\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9: \n",
    "Remove column Height and column Age from the existing referring dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name Qualification\n",
      "0   Ahmad           Msc\n",
      "1     Ali            MA\n",
      "2    Omar           Msc\n",
      "3  Hamzah           Msc\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"Height\", \"Age\"], axis = 1, inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.3 Adding new row to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 14:\n",
    "Adding a new row to the end of the Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  22000   30days      1000\n",
      "1  PySpark  25000   50days      2300\n",
      "2   Hadoop  23000   35days      1000\n",
      "3   Python  24000   40days      1200\n",
      "4   Pandas  26000   55days      2500\n",
      "-------------------------------\n",
      "    Courses    Fee Duration  Discount\n",
      "0     Spark  22000   30days      1000\n",
      "1   PySpark  25000   50days      2300\n",
      "2    Hadoop  23000   35days      1000\n",
      "3    Python  24000   40days      1200\n",
      "4    Pandas  26000   55days      2500\n",
      "5  Hyperion  27000   60days      2000\n"
     ]
    }
   ],
   "source": [
    "technologies= {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000],\n",
    "    'Duration':['30days','50days','35days', '40days','55days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500]\n",
    "}\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)\n",
    "print(\"-------------------------------\")\n",
    "# New list to append Row to DataFrame\n",
    "list = [\"Hyperion\", 27000, \"60days\", 2000]\n",
    "df.loc[len(df)] = list\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 10: \n",
    "use .iloc to insert the new row above into the second position of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "0     Spark  22000   30days      1000\n",
      "1   PySpark  25000   50days      2300\n",
      "2    Hadoop  23000   35days      1000\n",
      "3    Python  24000   40days      1200\n",
      "4    Pandas  26000   55days      2500\n",
      "5  Hyperion  27000   60days      2000\n",
      "-------------------------------\n",
      "    Courses    Fee Duration  Discount\n",
      "0     Spark  22000   30days      1000\n",
      "1  Hyperion  27000   60days      2000\n",
      "2   PySpark  25000   50days      2300\n",
      "3    Hadoop  23000   35days      1000\n",
      "4    Python  24000   40days      1200\n",
      "5    Pandas  26000   55days      2500\n",
      "6  Hyperion  27000   60days      2000\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(\"-------------------------------\")\n",
    "df1 = df.iloc[:1]\n",
    "\n",
    "df2 = df.iloc[1:]\n",
    "\n",
    "list = [\"Hyperion\", 27000, \"60days\", 2000]\n",
    "\n",
    "# Create a DataFrame for the new row\n",
    "list_df = pd.DataFrame([list], columns=df.columns)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df = pd.concat([df1, list_df, df2], ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.3 Deleting row From DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r1    Spark  20000    30day      1000\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000      NaN      1500\n",
      "r4   Python  22000     None      1200\n"
     ]
    }
   ],
   "source": [
    "technologies = {\n",
    "'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\"],\n",
    "'Fee' :[20000,25000,26000,22000],\n",
    "'Duration':['30day','40days',np.nan, None],\n",
    "'Discount':[1000,2300,1500,1200]\n",
    "}\n",
    "indexes=['r1','r2','r3','r4']\n",
    "df = pd.DataFrame(technologies,index=indexes)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 16:\n",
    "Drop rows by Index Labels or Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "r3  Hadoop  26000      NaN      1500\n",
      "r4  Python  22000     None      1200\n",
      "-------------------------------\n",
      "   Courses    Fee Duration  Discount\n",
      "r3  Hadoop  26000      NaN      1500\n",
      "r4  Python  22000     None      1200\n"
     ]
    }
   ],
   "source": [
    "# Drop rows by Index Label\n",
    "df1 = df.drop(['r1','r2'])\n",
    "print(df1)\n",
    "print(\"-------------------------------\")\n",
    "df1 = df.drop(index=['r1','r2'])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 17:\n",
    "Drop Rows by Index Number (Row Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "r1   Spark  20000    30day      1000\n",
      "r3  Hadoop  26000      NaN      1500\n",
      "-------------------------------\n",
      "    Courses    Fee Duration  Discount\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000      NaN      1500\n",
      "r4   Python  22000     None      1200\n",
      "-------------------------------\n",
      "    Courses    Fee Duration  Discount\n",
      "r1    Spark  20000    30day      1000\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000      NaN      1500\n",
      "-------------------------------\n",
      "    Courses    Fee Duration  Discount\n",
      "r1    Spark  20000    30day      1000\n",
      "r2  PySpark  25000   40days      2300\n"
     ]
    }
   ],
   "source": [
    "# Delete Rows 1 and 3 by Index numbers\n",
    "df1=df.drop(df.index[[1,3]])\n",
    "print(df1)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# Removes First Row\n",
    "df1=df.drop(df.index[0])\n",
    "print(df1)\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# Removes Last Row\n",
    "df1=df.drop(df.index[-1])\n",
    "print(df1)\n",
    "print(\"-------------------------------\")\n",
    "# Delete Rows by Index Range\n",
    "df1=df.drop(df.index[2:])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 18:\n",
    "Delete Rows with Default Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  20000    30day      1000\n",
      "1  PySpark  25000   40days      2300\n",
      "2   Hadoop  26000      NaN      1500\n",
      "3   Python  22000     None      1200\n",
      "-------------------------------\n",
      "   Courses    Fee Duration  Discount\n",
      "1  PySpark  25000   40days      2300\n",
      "2   Hadoop  26000      NaN      1500\n",
      "3   Python  22000     None      1200\n",
      "-------------------------------\n",
      "   Courses    Fee Duration  Discount\n",
      "1  PySpark  25000   40days      2300\n",
      "2   Hadoop  26000      NaN      1500\n",
      "-------------------------------\n",
      "  Courses    Fee Duration  Discount\n",
      "2  Hadoop  26000      NaN      1500\n",
      "3  Python  22000     None      1200\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Remove rows when you have a default index.\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)\n",
    "print(\"-------------------------------\")\n",
    "df1 = df.drop(0)\n",
    "print(df1)\n",
    "print(\"-------------------------------\")\n",
    "df3 = df.drop([0, 3])\n",
    "print(df3)\n",
    "print(\"-------------------------------\")\n",
    "df4 = df.drop(range(0,2))\n",
    "print(df4)\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the range(0,2) = [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 19: \n",
    "Drop Rows by Checking Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  20000    30day      1000\n",
      "1  PySpark  25000   40days      2300\n",
      "2   Hadoop  26000      NaN      1500\n",
      "3   Python  22000     None      1200\n",
      "-------------------------------\n",
      "  Courses    Fee Duration  Discount\n",
      "0   Spark  20000    30day      1000\n",
      "3  Python  22000     None      1200\n",
      "-------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [Courses, Fee, Duration, Discount]\n",
      "Index: []\n",
      "-------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [Courses, Fee, Duration, Discount]\n",
      "Index: []\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# Using drop() to delete rows based on column value\n",
    "df.drop(df[df['Fee'] >= 24000].index, inplace = True)\n",
    "print(df)\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# Remove rows\n",
    "df2 = df[df.Fee >= 24000]\n",
    "print(df2)\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "# Using loc\n",
    "df2 = df.loc[df[\"Fee\"] >= 24000]\n",
    "print(df2)\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 11: \n",
    "delete all rows with Fee >= 2200 and Discount == 2300. Save the result in a file named task.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  20000    30day      1000\n",
      "1  PySpark  25000   40days      2300\n",
      "2   Hadoop  26000      NaN      1500\n",
      "3   Python  22000      NaN      1200\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(technologies)\n",
    "condition1 = df['Fee'] > 23000\n",
    "condition2 = df['Discount'] == 1200\n",
    "condition = condition1 & condition2\n",
    "\n",
    "df.drop(df[condition].index, inplace = True)\n",
    "df.to_csv('task.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('task.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 12: \n",
    "Write a code to delete all rows with a Non/NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  20000    30day      1000\n",
      "1  PySpark  25000   40days      2300\n"
     ]
    }
   ],
   "source": [
    "#Task 12: Write a code to delete all rows with a Non/NaN value.\n",
    "df = pd.DataFrame(technologies)\n",
    "condition = df['Courses'].isnull() | df['Fee'].isnull() | df['Duration'].isnull() | df['Discount'].isnull()\n",
    "\n",
    "df.drop(df[condition].index, inplace = True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 13: \n",
    "Write a code to delete all rows having courses equal to Spark or Hadoop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "1  PySpark  25000   40days      2300\n",
      "3   Python  22000     None      1200\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(technologies)\n",
    "\n",
    "#Write a code to delete all rows having courses equal to Spark or Hadoop.\n",
    "condition1 = df['Courses'] == 'Spark' \n",
    "condition2 = df['Courses'] == 'Hadoop'\n",
    "\n",
    "condition = condition1 | condition2\n",
    "\n",
    "df.drop(df[condition].index, inplace = True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Combining DataFrames in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1 DataFrame Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "0  A4  B4  C4  D4\n",
      "1  A5  B5  C5  D5\n",
      "2  A6  B6  C6  D6\n",
      "3  A7  B7  C7  D7\n"
     ]
    }
   ],
   "source": [
    "# Create two sample DataFrames\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "        'D': ['D0', 'D1', 'D2', 'D3']\n",
    "    }\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "        'D': ['D4', 'D5', 'D6', 'D7']\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Concatenate the DataFrames vertically\n",
    "result = pd.concat([df1, df2])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 14: \n",
    "Perform the concatenation in the above example along columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D\n",
      "0  A0  B0  C0  D0  A4  B4  C4  D4\n",
      "1  A1  B1  C1  D1  A5  B5  C5  D5\n",
      "2  A2  B2  C2  D2  A6  B6  C6  D6\n",
      "3  A3  B3  C3  D3  A7  B7  C7  D7\n"
     ]
    }
   ],
   "source": [
    "# Create two sample DataFrames\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "        'D': ['D0', 'D1', 'D2', 'D3']\n",
    "    }\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "        'D': ['D4', 'D5', 'D6', 'D7']\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "result = pd.concat([df1, df2], axis=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1 DataFrame Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 15: \n",
    "Run the samples above and figure out what returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "   id value_df1  int_value1\n",
      "0   1         A           5\n",
      "1   2         B           6\n",
      "2   3         C           7\n",
      "3   4         D           8\n",
      "\n",
      "DataFrame 2:\n",
      "   id value_df2  int_value2\n",
      "0   3         E           1\n",
      "1   4         F           2\n",
      "2   5         G           3\n",
      "3   6         H           4\n"
     ]
    }
   ],
   "source": [
    "# Create first DataFrame\n",
    "df1 = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'value_df1': ['A', 'B', 'C', 'D'],\n",
    "    'int_value1': [5, 6, 7, 8]\n",
    "})\n",
    "\n",
    "# Create second DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    'id': [3, 4, 5, 6],\n",
    "    'value_df2': ['E', 'F', 'G', 'H'],\n",
    "    'int_value2': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame:\n",
      "   id value_df1  int_value1 value_df2  int_value2\n",
      "0   3         C           7         E           1\n",
      "1   4         D           8         F           2\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df1, df2, on='id')\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Left Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame:\n",
      "   id value_df1  int_value1 value_df2  int_value2\n",
      "0   1         A           5       NaN         NaN\n",
      "1   2         B           6       NaN         NaN\n",
      "2   3         C           7         E         1.0\n",
      "3   4         D           8         F         2.0\n"
     ]
    }
   ],
   "source": [
    "df = df1.merge(df2, on='id', how='left')\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Right Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame:\n",
      "   id value_df1  int_value1 value_df2  int_value2\n",
      "0   3         C         7.0         E           1\n",
      "1   4         D         8.0         F           2\n",
      "2   5       NaN         NaN         G           3\n",
      "3   6       NaN         NaN         H           4\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df1, df2, how='right')\n",
    "\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame:\n",
      "   id value_df1  int_value1 value_df2  int_value2\n",
      "0   1         A         5.0       NaN         NaN\n",
      "1   2         B         6.0       NaN         NaN\n",
      "2   3         C         7.0         E         1.0\n",
      "3   4         D         8.0         F         2.0\n",
      "4   5       NaN         NaN         G         3.0\n",
      "5   6       NaN         NaN         H         4.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df1, df2, how='outer')\n",
    "\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Left Anti-Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id value_df1  int_value1\n",
      "0   1         A           5\n",
      "1   2         B           6\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.merge(df2, on='id', how='left', indicator=True)\n",
    "df = df3.loc[df3['_merge'] == 'left_only', 'id']\n",
    "\n",
    "d = df1[df1['id'].isin(df)]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Right Anti-Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id value_df2  int_value2\n",
      "2   5         G           3\n",
      "3   6         H           4\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.merge(df2, on='id', how='right', indicator=True)\n",
    "df = df3.loc[df3['_merge'] == 'right_only', 'id']\n",
    "d = df2[df2['id'].isin(df)]\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Anti-Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id value_df1  int_value1 value_df2  int_value2      _merge\n",
      "0   1         A         5.0       NaN         NaN   left_only\n",
      "1   2         B         6.0       NaN         NaN   left_only\n",
      "4   5       NaN         NaN         G         3.0  right_only\n",
      "5   6       NaN         NaN         H         4.0  right_only\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.merge(df2,on='id', how='outer', indicator=True)\n",
    "df = df3.loc[df3['_merge'] == 'both', 'id']\n",
    "d = df3[~df3['id'].isin(df)]\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merging on Different Column Names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_x value_df1  int_value1  id_y value_df2  int_value2\n",
      "0     1         A           5     3         E           1\n",
      "1     2         B           6     4         F           2\n",
      "2     3         C           7     5         G           3\n",
      "3     4         D           8     6         H           4\n"
     ]
    }
   ],
   "source": [
    "# Merging on Dierent Column Names.\n",
    "\n",
    "df = df1.merge(df2, left_on='id', right_on='int_value2')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merging on Multiple Columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, value_df1, int_value1, value_df2, int_value2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = df1.merge(df2, left_on=['id', 'int_value1'], right_on=['id', 'int_value2'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 16:\n",
    "Let’s say that we want to merge frames df1 and df2 using a left outer join,\n",
    "Select all the columns from df1 but only column colE from df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "   id value_df1  int_value1\n",
      "0   1         A           5\n",
      "1   2         B           6\n",
      "2   3         C           7\n",
      "3   4         D           8\n",
      "\n",
      "DataFrame 2:\n",
      "   id value_df2  int_value2\n",
      "0   3         E           1\n",
      "1   4         F           2\n",
      "2   5         G           3\n",
      "3   6         H           4\n"
     ]
    }
   ],
   "source": [
    "# Create first DataFrame\n",
    "df1 = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'value_df1': ['A', 'B', 'C', 'D'],\n",
    "    'int_value1': [5, 6, 7, 8]\n",
    "})\n",
    "\n",
    "# Create second DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    'id': [3, 4, 5, 6],\n",
    "    'value_df2': ['E', 'F', 'G', 'H'],\n",
    "    'int_value2': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame:\n",
      "   id value_df1  int_value1 value_df2\n",
      "0   1         A           5       NaN\n",
      "1   2         B           6       NaN\n",
      "2   3         C           7         E\n",
      "3   4         D           8         F\n"
     ]
    }
   ],
   "source": [
    "# but only column value_df2 from df2.\n",
    "\n",
    "df = df1.merge(df2[['id','value_df2']], on='id', how='left')\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
