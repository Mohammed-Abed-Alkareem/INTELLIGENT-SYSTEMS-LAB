{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment #7: Introduction to Deep Learning with PyTorch\n",
    "<b>Mohammed Abed Alkareem</b>\n",
    "<b>1210708</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. From a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. From another tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.4767, 0.3808],\n",
      "        [0.2664, 0.6272]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides thedatatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. With random or constant values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.8154, 0.5865, 0.4935],\n",
      "        [0.7647, 0.6088, 0.6379]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9163, 0.4588, 0.4744, 0.5896],\n",
       "        [0.3302, 0.7021, 0.9076, 0.2633],\n",
       "        [0.2304, 0.6678, 0.4232, 0.0277]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Standard numpy-like indexing and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Joining tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Multiplying tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. In-place operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridge with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor to NumPy array: A change in the tensor reflects in the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy array to Tensor: Changes in the NumPy array reflects in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 A Gentle Introduction to torch.autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiation in Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  65.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We create another tensor Q from a and b.\n",
    "##              Q = 3a3 − b2\n",
    "\n",
    "Q = 3*a**3 - b**2\n",
    "\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 81.])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  -8.])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "# check if collected gradients are correct\n",
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-48.,  33.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We create another tensor Q from a and b.\n",
    "##              Q = 3a3 − ab2\n",
    "\n",
    "Q = 3*a**3 - a*b**2\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 81.])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  -8.])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:\n",
    "  Use  autograd  to  compute  the  gradients  of Y w.r.t. x1 and x2 at  the  point(x1, x2) = (1,1).  \n",
    "  WhereY= (3x1−2x2−2)2.Verify your results by computing the gradients analytically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor(1.0, requires_grad=True)\n",
    "x2 = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "Y = (3*x1 -2 * x2 -2)**2\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with respect to x1: -6.0\n",
      "Gradient with respect to x2: 4.0\n"
     ]
    }
   ],
   "source": [
    "Y.backward()\n",
    "\n",
    "# Print the gradients\n",
    "gradient_x1 = x1.grad\n",
    "gradient_x2 = x2.grad\n",
    "\n",
    "print(\"Gradient with respect to x1:\", gradient_x1.item())\n",
    "print(\"Gradient with respect to x2:\", gradient_x2.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ∂Y/∂x1 = 6(3x1−2x2−2)\n",
    "\n",
    "X1 = 1 , x2 = 1 ==> ∂Y/∂x1 = 6*3*1 - 12*1 -12 = -6\n",
    "\n",
    "- ∂Y/∂x2 = -4(3x1−2x2−2)\n",
    "\n",
    "X1 = 1 , x2 = 1 ==> ∂Y/∂x1 = -4*3*1 + 8*1 + 8 = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3    Building Models with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        # # 784 is the input dimension, and 64 is the output dimenstion of the first hidden layer\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # apply the first layer with relu activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "\n",
    "print(len(params))\n",
    "\n",
    "for p in params:\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2:  \n",
    "Identify what are the parameters that are printed in the previous code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.Size([64, 784])\n",
    "\n",
    "    for layer 1 784 input , 64 output\n",
    "    \n",
    "\n",
    "- torch.Size([64])\n",
    "\n",
    "    the output from the first layer out of the activation function\n",
    "\n",
    "- torch.Size([64, 64])\n",
    "\n",
    "    for layer 2 64 input , 64 output\n",
    "\n",
    "- torch.Size([64])\n",
    "\n",
    "    the output from the second layer out of the activation function\n",
    "\n",
    "\n",
    "- torch.Size([10, 64])\n",
    "\n",
    "    for layer 2 64 input , 10 output\n",
    "\n",
    "\n",
    "- torch.Size([10])\n",
    "\n",
    "    the output from the third (output) layer out of the activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0457, -0.0549, -0.0703,  0.0954,  0.0818, -0.0271, -0.0146, -0.1218,\n",
      "          0.1902,  0.1087]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 784)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3:  \n",
    "Try  the  previous  network  with  a  random  mini-batch  of  size  4  and  print  its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0808, -0.1087, -0.0060,  0.0022,  0.2577,  0.0370,  0.0229, -0.1074,\n",
      "          0.1696,  0.0552],\n",
      "        [ 0.1420,  0.1253, -0.0065,  0.2226,  0.0693,  0.0549,  0.0085, -0.1136,\n",
      "          0.1699,  0.0086],\n",
      "        [-0.0685, -0.0203, -0.0648,  0.1489,  0.1312,  0.1040,  0.0830, -0.1470,\n",
      "          0.2108,  0.1878],\n",
      "        [-0.0281, -0.0322,  0.1634, -0.0907,  0.1607, -0.0963,  0.0976, -0.0896,\n",
      "         -0.0808,  0.0461]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(4, 784)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.MNIST(root=\"data\",\n",
    "                               train=True,\n",
    "                               download=True,\n",
    "                               transform=ToTensor()\n",
    "                               )\n",
    "\n",
    "test_data = datasets.MNIST(root=\"data\",\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=ToTensor()\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating and Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(\"digit:\" + str(label))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing your data for training with DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate through the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([4, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.369\n",
      "[1,  4000] loss: 0.349\n",
      "[1,  6000] loss: 0.337\n",
      "[1,  8000] loss: 0.340\n",
      "[1, 10000] loss: 0.346\n",
      "[1, 12000] loss: 0.349\n",
      "[1, 14000] loss: 0.331\n",
      "Finished Training\n",
      "[2,  2000] loss: 0.321\n",
      "[2,  4000] loss: 0.307\n",
      "[2,  6000] loss: 0.295\n",
      "[2,  8000] loss: 0.304\n",
      "[2, 10000] loss: 0.305\n",
      "[2, 12000] loss: 0.304\n",
      "[2, 14000] loss: 0.299\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.flatten(inputs,1))\n",
    "        iteration_loss = loss(outputs, labels)\n",
    "        iteration_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += iteration_loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4:  \n",
    "What  is  the  meaning  of epoch,forward pass,backward pass.What  isthe effect of torch.flatten(inputs, 1),and optimizer.step()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Epoch**\n",
    "An epoch is one complete pass through the entire training dataset. When you train a model, you often go through the dataset multiple times to adjust the model's parameters and improve its performance. Each complete cycle through the dataset is called an epoch.\n",
    "\n",
    "- **Forward Pass**\n",
    "A forward pass is the process of passing the input data through the neural network to get the output (predictions). This involves computing the values at each layer of the network starting from the input layer and moving to the output layer.\n",
    "\n",
    "- **Backward Pass**\n",
    "A backward pass is the process of computing the gradients (how much each parameter should change) after the forward pass. This is done using a technique called backpropagation, which helps in minimizing the error by updating the model’s parameters. Essentially, it tells the model how to change to make better predictions.\n",
    "\n",
    "- **Effect of torch.flatten(inputs, 1)**\n",
    "The torch.flatten(inputs, 1) function takes the input tensor and flattens it starting from the first dimension. This means it converts a multi-dimensional input into a 2D tensor, where each input example becomes a single row. For example, if the input is a batch of images, this function will flatten each image into a single row vector, making it easier to feed into fully connected layers in a neural network.\n",
    "\n",
    "- **optimizer.step()**\n",
    "The optimizer.step() function updates the model’s parameters based on the computed gradients. After the forward and backward passes, the optimizer uses the gradients to adjust the parameters in an attempt to reduce the error. This step moves the parameters slightly in the direction that reduces the error, helping the model learn and improve over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH ='./my_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22232\\238682776.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(PATH))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(torch.flatten(images,1))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5:  \n",
    "Train  the  network  in  the  previous  example,  but  instead  of  using  2  hiddenlayers, try 3 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        # # 784 is the input dimension, and 64 is the output dimenstion of the first hidden layer\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # apply the first layer with relu activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.305\n",
      "[1,  4000] loss: 2.303\n",
      "[1,  6000] loss: 2.304\n",
      "[1,  8000] loss: 2.304\n",
      "[1, 10000] loss: 2.304\n",
      "[1, 12000] loss: 2.304\n",
      "[1, 14000] loss: 2.304\n",
      "[2,  2000] loss: 2.304\n",
      "[2,  4000] loss: 2.304\n",
      "[2,  6000] loss: 2.304\n",
      "[2,  8000] loss: 2.304\n",
      "[2, 10000] loss: 2.304\n",
      "[2, 12000] loss: 2.303\n",
      "[2, 14000] loss: 2.305\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.flatten(inputs,1))\n",
    "        iteration_loss = loss(outputs, labels)\n",
    "        iteration_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += iteration_loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6:  \n",
    "Train the network in the previous example using Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        # # 784 is the input dimension, and 64 is the output dimenstion of the first hidden layer\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # apply the first layer with relu activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.565\n",
      "Finished Training\n",
      "[1,  4000] loss: 0.299\n",
      "Finished Training\n",
      "[1,  6000] loss: 0.244\n",
      "Finished Training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(torch\u001b[38;5;241m.\u001b[39mflatten(inputs,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     13\u001b[0m iteration_loss \u001b[38;5;241m=\u001b[39m loss(outputs, labels)\n\u001b[1;32m---> 14\u001b[0m \u001b[43miteration_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.flatten(inputs,1))\n",
    "        iteration_loss = loss(outputs, labels)\n",
    "        iteration_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += iteration_loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "            print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc6): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        # # 784 is the input dimension, and 64 is the output dimenstion of the first hidden layer\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.fc5 = nn.Linear(64, 64)\n",
    "        self.fc6 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # apply the first layer with relu activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc6): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7:  \n",
    "Train the network in the previous example on GPU. Do you notice significantspeedup?  if not, try to increase the size of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.305\n",
      "[1,  4000] loss: 2.303\n",
      "[1,  6000] loss: 2.301\n",
      "[1,  8000] loss: 2.300\n",
      "[1, 10000] loss: 2.298\n",
      "[1, 12000] loss: 2.298\n",
      "[1, 14000] loss: 2.295\n",
      "Finished Training\n",
      "[2,  2000] loss: 2.292\n",
      "[2,  4000] loss: 2.285\n",
      "[2,  6000] loss: 2.278\n",
      "[2,  8000] loss: 2.262\n",
      "[2, 10000] loss: 2.225\n",
      "[2, 12000] loss: 2.157\n",
      "[2, 14000] loss: 2.031\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move inputs and labels to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.flatten(inputs,1))\n",
    "        iteration_loss = loss(outputs, labels)\n",
    "        iteration_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += iteration_loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
